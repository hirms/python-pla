{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author : Remus !!\n",
    "Date : 2015.09.07\n",
    "\n",
    "Exercise:\n",
    "- Calculate surivival rate for titianic scenario from Kaggle\n",
    "- Use Perceptron Learning Algorithm (PLA) from sklearn kit\n",
    "\n",
    "Assumption:\n",
    "- This exercise does not include the ordinary \"data exploration\" step, as this step has been carried out by other exercise.\n",
    "\n",
    "Steps:\n",
    "0. Import project packages\n",
    "1. Data Cleanup\n",
    "2. Fit the model\n",
    "3. Predict the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv as csv\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data Cleanup\n",
    "- Convert all strings to interger classifers\n",
    "- Fill in the missing values of the data and make it complete\n",
    "- Do for both \"training\" and \"test\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DATA : Training data\n",
    "train_df = pd.read_csv('train.csv', header=0)        # Load the train file into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/ipykernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# SEX => GENDER : female = 0, Male = 1\n",
    "train_df['Gender'] = train_df['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "\n",
    "# ==============================================================================\n",
    "# EMBARKED : Embarked from 'C', 'Q', 'S'\n",
    "# Note this is not ideal: in translating categories to numbers, Port \"2\" is not 2 times greater than Port \"1\", etc.\n",
    "\n",
    "# All missing Embarked -> just make them embark from most common place\n",
    "if len(train_df.Embarked[ train_df.Embarked.isnull() ]) > 0:\n",
    "    train_df.Embarked[ train_df.Embarked.isnull() ] = train_df.Embarked.dropna().mode().values\n",
    "\n",
    "Ports = list(enumerate(np.unique(train_df['Embarked'])))    # determine all values of Embarked,\n",
    "Ports_dict = { name : i for i, name in Ports }              # set up a dictionary in the form  Ports : index\n",
    "train_df.Embarked = train_df.Embarked.map( lambda x: Ports_dict[x]).astype(int)     # Convert all Embark strings to int\n",
    "\n",
    "# ==============================================================================\n",
    "# AGE : All the ages with no data -> make the median of all Ages\n",
    "median_age = train_df['Age'].dropna().median()\n",
    "if len(train_df.Age[ train_df.Age.isnull() ]) > 0:\n",
    "    train_df.loc[ (train_df.Age.isnull()), 'Age'] = median_age\n",
    "\n",
    "# ==============================================================================\n",
    "# All the missing Fares -> assume median of their respective class\n",
    "if len(train_df.Fare[ train_df.Fare.isnull() ]) > 0:\n",
    "    median_fare = np.zeros(3)\n",
    "    for f in range(0,3):                                              # loop 0 to 2\n",
    "        median_fare[f] = train_df[ train_df.Pclass == f+1 ]['Fare'].dropna().median()\n",
    "    for f in range(0,3):                                              # loop 0 to 2\n",
    "        train_df.loc[ (train_df.Fare.isnull()) & (train_df.Pclass == f+1 ), 'Fare'] = median_fare[f]    \n",
    "\n",
    "# ==============================================================================\n",
    "# Remove the Name column, Cabin, Ticket, and Sex (since I copied and filled it to Gender)\n",
    "train_df = train_df.drop(['Name', 'Sex', 'Ticket', 'Cabin', 'PassengerId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DATA : TEST DATA\n",
    "test_df = pd.read_csv('test.csv', header=0)        # Load the test file into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SEX => GENDER : female = 0, Male = 1\n",
    "test_df['Gender'] = test_df['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "\n",
    "# ==============================================================================\n",
    "# EMBARKED : Embarked from 'C', 'Q', 'S'\n",
    "# All missing Embarked -> just make them embark from most common place\n",
    "if len(test_df.Embarked[ test_df.Embarked.isnull() ]) > 0:\n",
    "    test_df.Embarked[ test_df.Embarked.isnull() ] = test_df.Embarked.dropna().mode().values\n",
    "# Again convert all Embarked strings to int\n",
    "test_df.Embarked = test_df.Embarked.map( lambda x: Ports_dict[x]).astype(int)\n",
    "\n",
    "# ==============================================================================\n",
    "# AGE : All the ages with no data -> make the median of all Ages\n",
    "median_age = test_df['Age'].dropna().median()\n",
    "if len(test_df.Age[ test_df.Age.isnull() ]) > 0:\n",
    "    test_df.loc[ (test_df.Age.isnull()), 'Age'] = median_age\n",
    "\n",
    "# ==============================================================================\n",
    "# All the missing Fares -> assume median of their respective class\n",
    "if len(test_df.Fare[ test_df.Fare.isnull() ]) > 0:\n",
    "    median_fare = np.zeros(3)\n",
    "    for f in range(0,3):                                              # loop 0 to 2\n",
    "        median_fare[f] = test_df[ test_df.Pclass == f+1 ]['Fare'].dropna().median()\n",
    "    for f in range(0,3):                                              # loop 0 to 2\n",
    "        test_df.loc[ (test_df.Fare.isnull()) & (test_df.Pclass == f+1 ), 'Fare'] = median_fare[f]\n",
    "\n",
    "# ==============================================================================\n",
    "# Collect the test data's PassengerIds before dropping it\n",
    "ids = test_df['PassengerId'].values\n",
    "# Remove the Name column, Cabin, Ticket, and Sex (since I copied and filled it to Gender)\n",
    "test_df = test_df.drop(['Name', 'Sex', 'Ticket', 'Cabin', 'PassengerId'], axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Fit the model\n",
    "- Convert the data from dataframe back to numpy array\n",
    "- Fit the model : Perceptron Learning Algorithm (PLA) from sklearn kit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The data is now ready to go. So lets fit to the train, then predict to the test!\n",
    "# Convert back to a numpy array\n",
    "train_data = train_df.values\n",
    "test_data = test_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    }
   ],
   "source": [
    "print 'Training...'\n",
    "#forest = RandomForestClassifier(n_estimators=100)\n",
    "#forest = forest.fit( train_data[0::,1::], train_data[0::,0] )\n",
    "\n",
    "pla = Perceptron(n_iter=50)\n",
    "pla = pla.fit( train_data[0::,1::], train_data[0::,0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Predict the TEST dataset\n",
    "- Make prediction on the \"test.csv\" dataset\n",
    "- Output prediction outcomes to a new file \"titanic_pla.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n"
     ]
    }
   ],
   "source": [
    "print 'Predicting...'\n",
    "#output = forest.predict(test_data).astype(int)\n",
    "output = pla.predict(test_data).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "predictions_file = open(\"titanic_pla.csv\", \"wb\")\n",
    "open_file_object = csv.writer(predictions_file)\n",
    "open_file_object.writerow([\"PassengerId\",\"Survived\"])\n",
    "open_file_object.writerows(zip(ids, output))\n",
    "predictions_file.close()\n",
    "print 'Done.'"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
